{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715},{"sourceId":7203508,"sourceType":"datasetVersion","datasetId":4167194}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Speech and Natural Language Processing (SNLP)\n\n## Lab03 (Part01) \n## RNNs and LSTMs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-06T04:18:05.013518Z","iopub.execute_input":"2024-10-06T04:18:05.014279Z","iopub.status.idle":"2024-10-06T04:18:06.036242Z","shell.execute_reply.started":"2024-10-06T04:18:05.014243Z","shell.execute_reply":"2024-10-06T04:18:06.035153Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/glove-6b-100-d/glove.6B.100d.txt\n/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch import nn\nfrom torch.optim import Adam","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:18:10.124546Z","iopub.execute_input":"2024-10-06T04:18:10.125024Z","iopub.status.idle":"2024-10-06T04:18:13.983927Z","shell.execute_reply.started":"2024-10-06T04:18:10.124988Z","shell.execute_reply":"2024-10-06T04:18:13.982943Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the IMDB dataset\ndf = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:30:44.333766Z","iopub.execute_input":"2024-10-06T04:30:44.334604Z","iopub.status.idle":"2024-10-06T04:30:44.964812Z","shell.execute_reply.started":"2024-10-06T04:30:44.334560Z","shell.execute_reply":"2024-10-06T04:30:44.963921Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:30:46.788362Z","iopub.execute_input":"2024-10-06T04:30:46.788765Z","iopub.status.idle":"2024-10-06T04:30:46.808731Z","shell.execute_reply.started":"2024-10-06T04:30:46.788725Z","shell.execute_reply":"2024-10-06T04:30:46.807785Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"review       0\nsentiment    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nimport nltk\n\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:30:48.098073Z","iopub.execute_input":"2024-10-06T04:30:48.098460Z","iopub.status.idle":"2024-10-06T04:30:48.105698Z","shell.execute_reply.started":"2024-10-06T04:30:48.098424Z","shell.execute_reply":"2024-10-06T04:30:48.104763Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocess text (remove HTML tags, punctuation, lowercase)\ndef preprocess_text(text):\n    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags\n    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n    text = text.lower()  # Convert to lowercase\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:30:49.424681Z","iopub.execute_input":"2024-10-06T04:30:49.425462Z","iopub.status.idle":"2024-10-06T04:30:49.430493Z","shell.execute_reply.started":"2024-10-06T04:30:49.425420Z","shell.execute_reply":"2024-10-06T04:30:49.429414Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df['review'] = df['review'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:30:50.792107Z","iopub.execute_input":"2024-10-06T04:30:50.792820Z","iopub.status.idle":"2024-10-06T04:30:52.420635Z","shell.execute_reply.started":"2024-10-06T04:30:50.792782Z","shell.execute_reply":"2024-10-06T04:30:52.419746Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Convert sentiment labels to binary (positive=1, negative=0)\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['sentiment'])  # 0 for negative, 1 for positive\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:31:25.285560Z","iopub.execute_input":"2024-10-06T04:31:25.286266Z","iopub.status.idle":"2024-10-06T04:31:25.308857Z","shell.execute_reply.started":"2024-10-06T04:31:25.286223Z","shell.execute_reply":"2024-10-06T04:31:25.307945Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                              review  sentiment  label\n0  one of the other reviewers has mentioned that ...          1      1\n1  a wonderful little production the filming tech...          1      1\n2  i thought this was a wonderful way to spend ti...          1      1\n3  basically theres a family where a little boy j...          0      0\n4  petter matteis love in the time of money is a ...          1      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other reviewers has mentioned that ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonderful little production the filming tech...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought this was a wonderful way to spend ti...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically theres a family where a little boy j...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter matteis love in the time of money is a ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.drop('label', axis=1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:33:01.220372Z","iopub.execute_input":"2024-10-06T04:33:01.221260Z","iopub.status.idle":"2024-10-06T04:33:01.234591Z","shell.execute_reply.started":"2024-10-06T04:33:01.221219Z","shell.execute_reply":"2024-10-06T04:33:01.233437Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                              review  sentiment\n0  one of the other reviewers has mentioned that ...          1\n1  a wonderful little production the filming tech...          1\n2  i thought this was a wonderful way to spend ti...          1\n3  basically theres a family where a little boy j...          0\n4  petter matteis love in the time of money is a ...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other reviewers has mentioned that ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonderful little production the filming tech...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought this was a wonderful way to spend ti...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically theres a family where a little boy j...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter matteis love in the time of money is a ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:34:02.659699Z","iopub.execute_input":"2024-10-06T04:34:02.660466Z","iopub.status.idle":"2024-10-06T04:34:02.673660Z","shell.execute_reply.started":"2024-10-06T04:34:02.660423Z","shell.execute_reply":"2024-10-06T04:34:02.672759Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"## Load GloVe embeddings\n\nembedding_dim = 100\nglove_path = '/kaggle/input/glove-6b-100-d/glove.6B.100d.txt'\nembedding_index = {}\n\nwith open(glove_path, 'r', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        vector = np.asarray(values[1:], dtype='float32')\n        embedding_index[word] = vector\n\n# Tokenize the text\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train)\nvocab_size = len(tokenizer.word_index) + 1\n\n# Convert texts to sequences and pad them\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\n\nmax_length = 100  # Define max length for padding\nX_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\nX_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n\n# Create embedding matrix\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor word, idx in tokenizer.word_index.items():\n    if word in embedding_index:\n        embedding_matrix[idx] = embedding_index[word]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:36:15.301237Z","iopub.execute_input":"2024-10-06T04:36:15.301623Z","iopub.status.idle":"2024-10-06T04:36:56.236949Z","shell.execute_reply.started":"2024-10-06T04:36:15.301586Z","shell.execute_reply":"2024-10-06T04:36:56.235861Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class IMDBDataset(Dataset):\n    def __init__(self, reviews, labels):\n        self.reviews = reviews\n        self.labels = labels\n    \n    def __len__(self):\n        return len(self.reviews)\n    \n    def __getitem__(self, idx):\n        review = torch.tensor(self.reviews[idx], dtype=torch.long)\n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n        return review, label","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:37:41.340430Z","iopub.execute_input":"2024-10-06T04:37:41.341200Z","iopub.status.idle":"2024-10-06T04:37:41.347655Z","shell.execute_reply.started":"2024-10-06T04:37:41.341145Z","shell.execute_reply":"2024-10-06T04:37:41.346718Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader for training and testing\ntrain_dataset = IMDBDataset(X_train_pad, y_train.values)\ntest_dataset = IMDBDataset(X_test_pad, y_test.values)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) ","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:37:43.470180Z","iopub.execute_input":"2024-10-06T04:37:43.470606Z","iopub.status.idle":"2024-10-06T04:37:43.476015Z","shell.execute_reply.started":"2024-10-06T04:37:43.470563Z","shell.execute_reply":"2024-10-06T04:37:43.475130Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Vanilla RNNs Model\n\nclass VanillaRNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix):\n        super(VanillaRNN, self).__init__()\n        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        h0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)  # Initial hidden state\n        out, _ = self.rnn(x, h0)\n        out = self.fc(out[:, -1, :])  # Use the output of the last time step\n        return out\n\n# Model parameters\nembedding_dim = 100\nhidden_dim = 128\noutput_dim = 1\n\n# Initialize model, loss function, and optimizer\nRNN_Model = VanillaRNN(vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = Adam(RNN_Model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:38:45.916585Z","iopub.execute_input":"2024-10-06T04:38:45.916984Z","iopub.status.idle":"2024-10-06T04:38:47.442959Z","shell.execute_reply.started":"2024-10-06T04:38:45.916945Z","shell.execute_reply":"2024-10-06T04:38:47.442167Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Training function\ndef train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        for reviews, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(reviews)\n            loss = criterion(outputs.squeeze(), labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}')\n\n# Train the Vanilla RNN model\ntrain_model(RNN_Model, train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:39:00.778035Z","iopub.execute_input":"2024-10-06T04:39:00.779083Z","iopub.status.idle":"2024-10-06T04:43:03.367872Z","shell.execute_reply.started":"2024-10-06T04:39:00.779039Z","shell.execute_reply":"2024-10-06T04:43:03.367023Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch 1/5, Loss: 0.6664\nEpoch 2/5, Loss: 0.6616\nEpoch 3/5, Loss: 0.6607\nEpoch 4/5, Loss: 0.6648\nEpoch 5/5, Loss: 0.6616\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## LSTM Model\n\nclass LSTMModel(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix):\n        super(LSTMModel, self).__init__()\n        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        h0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)  # Initial hidden state\n        c0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)  # Initial cell state\n        out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :])  # Use the output of the last time step\n        return out\n\n# Initialize model, loss function, and optimizer\nLSTM_Model = LSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = Adam(LSTM_Model.parameters(), lr=0.001)\n\n# Train the LSTM model\ntrain_model(LSTM_Model, train_loader, criterion, optimizer, num_epochs=7)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:44:23.415441Z","iopub.execute_input":"2024-10-06T04:44:23.415932Z","iopub.status.idle":"2024-10-06T04:48:00.129111Z","shell.execute_reply.started":"2024-10-06T04:44:23.415863Z","shell.execute_reply":"2024-10-06T04:48:00.127989Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/7, Loss: 0.5990\nEpoch 2/7, Loss: 0.4310\nEpoch 3/7, Loss: 0.3682\nEpoch 4/7, Loss: 0.3296\nEpoch 5/7, Loss: 0.2978\nEpoch 6/7, Loss: 0.2730\nEpoch 7/7, Loss: 0.2464\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Vanilla RNNS with on-the-fly embeddings\n\nclass VanillaRNNOnTheFly(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n        super(VanillaRNNOnTheFly, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        h0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)  # Initial hidden state\n        out, _ = self.rnn(x, h0)\n        out = self.fc(out[:, -1, :])  # Use the output of the last time step\n        return out\n\n# Initialize model, loss function, and optimizer\nRNN_withOTF_Model = VanillaRNNOnTheFly(vocab_size, embedding_dim, hidden_dim, output_dim)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = Adam(RNN_withOTF_Model.parameters(), lr=0.001)\n\n# Train the Vanilla RNN model with on-the-fly embeddings\ntrain_model(RNN_withOTF_Model, train_loader, criterion, optimizer, num_epochs=7)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T04:51:47.807475Z","iopub.execute_input":"2024-10-06T04:51:47.808206Z","iopub.status.idle":"2024-10-06T05:27:11.982549Z","shell.execute_reply.started":"2024-10-06T04:51:47.808163Z","shell.execute_reply":"2024-10-06T05:27:11.981668Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/7, Loss: 0.6713\nEpoch 2/7, Loss: 0.6198\nEpoch 3/7, Loss: 0.5754\nEpoch 4/7, Loss: 0.5487\nEpoch 5/7, Loss: 0.5365\nEpoch 6/7, Loss: 0.5140\nEpoch 7/7, Loss: 0.5366\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## LSTM with on-the-fly embeddings\n\nclass LSTMModelOnTheFly(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n        super(LSTMModelOnTheFly, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        h0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)  # Initial hidden state\n        c0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)  # Initial cell state\n        out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :])  # Use the output of the last time step\n        return out\n\n# Initialize model, loss function, and optimizer\nLSTM_withOTF_Model = LSTMModelOnTheFly(vocab_size, embedding_dim, hidden_dim, output_dim)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = Adam(LSTM_withOTF_Model.parameters(), lr=0.001)\n\n# Train the LSTM model with on-the-fly embeddings\ntrain_model(LSTM_withOTF_Model, train_loader, criterion, optimizer, num_epochs=5) ","metadata":{"execution":{"iopub.status.busy":"2024-10-06T05:28:37.453472Z","iopub.execute_input":"2024-10-06T05:28:37.454254Z","iopub.status.idle":"2024-10-06T05:50:04.860640Z","shell.execute_reply.started":"2024-10-06T05:28:37.454212Z","shell.execute_reply":"2024-10-06T05:50:04.859607Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 1/5, Loss: 0.6073\nEpoch 2/5, Loss: 0.4935\nEpoch 3/5, Loss: 0.2962\nEpoch 4/5, Loss: 0.2001\nEpoch 5/5, Loss: 0.1279\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to evaluate the model\ndef Evaluate_Model(model, test_loader, criterion):\n    model.eval()\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n    \n    with torch.no_grad():\n        for reviews, labels in test_loader:\n            outputs = model(reviews)\n            loss = criterion(outputs.squeeze(), labels)\n            total_loss += loss.item()\n            \n            # Convert logits to probabilities and then to binary predictions\n            predictions = torch.round(torch.sigmoid(outputs.squeeze()))\n            correct_predictions += (predictions == labels).sum().item()\n            total_predictions += labels.size(0)\n    \n    avg_loss = total_loss / len(test_loader)\n    accuracy = correct_predictions / total_predictions\n    return avg_loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-10-06T05:55:41.109044Z","iopub.execute_input":"2024-10-06T05:55:41.109435Z","iopub.status.idle":"2024-10-06T05:55:41.116860Z","shell.execute_reply.started":"2024-10-06T05:55:41.109398Z","shell.execute_reply":"2024-10-06T05:55:41.115905Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Evaluating the Vanilla RNN model with GloVe embeddings\nRNN_Loss, RNN_Accuracy = Evaluate_Model(Model_RNN, test_loader, criterion)\nprint(f\"Vanilla RNN with GloVe Embeddings - Loss: {RNN_Loss:.4f}, Accuracy: {RNN_Accuracy:.4f}\")\n\n# Evaluating the Vanilla RNN model with on-the-fly embeddings\nRNN_WithOTF_Loss, RNN_WithOTF_Accuracy = Evaluate_Model(RNN_withOTF_Model, test_loader, criterion)\nprint(f\"Vanilla RNN with On-the-Fly Embeddings - Loss: {RNN_WithOTF_Loss:.4f}, Accuracy: {RNN_WithOTF_Accuracy:.4f}\") ","metadata":{"execution":{"iopub.status.busy":"2024-10-06T05:58:14.344171Z","iopub.execute_input":"2024-10-06T05:58:14.344849Z","iopub.status.idle":"2024-10-06T05:58:18.316019Z","shell.execute_reply.started":"2024-10-06T05:58:14.344810Z","shell.execute_reply":"2024-10-06T05:58:18.314944Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Vanilla RNN with GloVe Embeddings - Loss: 0.6612, Accuracy: 0.5826\nVanilla RNN with On-the-Fly Embeddings - Loss: 0.6238, Accuracy: 0.6944\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluating the LSTM model with GloVe embeddings\nLSTM_Loss, LSTM_Accuracy = Evaluate_Model(LSTM_Model, test_loader, criterion)\nprint(f\"LSTM with GloVe Embeddings - Loss: {LSTM_Loss:.4f}, Accuracy: {LSTM_Accuracy:.4f}\")\n\n# Evaluating the LSTM model with on-the-fly embeddings\nLSTM_withOTF_Loss, LSTM_withOTF_Accuracy = Evaluate_Model(LSTM_withOTF_Model, test_loader, criterion)\nprint(f\"LSTM with On-the-Fly Embeddings - Loss: {LSTM_withOTF_Loss:.4f}, Accuracy: {LSTM_withOTF_Accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-06T05:58:37.235026Z","iopub.execute_input":"2024-10-06T05:58:37.235880Z","iopub.status.idle":"2024-10-06T05:58:41.390692Z","shell.execute_reply.started":"2024-10-06T05:58:37.235840Z","shell.execute_reply":"2024-10-06T05:58:41.389686Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"LSTM with GloVe Embeddings - Loss: 0.3163, Accuracy: 0.8675\nLSTM with On-the-Fly Embeddings - Loss: 0.3922, Accuracy: 0.8507\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}